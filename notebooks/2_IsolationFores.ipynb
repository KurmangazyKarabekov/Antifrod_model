{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\"))\n",
    "sys.path.append(src_path)\n",
    "from utils import lift_metric_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_data = pl.read_csv(\"/Users/kurmangazykarabekov/Desktop/собесы/12Go Asia/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conver date from object to datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/p8dmtkcx40g8jtfzctxzg4km0000gn/T/ipykernel_4737/1105408612.py:28: ChronoFormatWarning: Detected the pattern `.%f` in the chrono format string. This pattern should not be used to parse values after a decimal point. Use `%.f` instead. See the full specification: https://docs.rs/chrono/latest/chrono/format/strftime\n",
      "  .str.strptime(pl.Datetime, format=\"%Y-%m-%d %H:%M:%S.%f%z\", strict=False)\n"
     ]
    }
   ],
   "source": [
    "pl_data = (\n",
    "    pl_data.with_columns(\n",
    "        pl.col(\"createdon\")\n",
    "        .str.strptime(\n",
    "            pl.Datetime,\n",
    "            format=\"%Y-%m-%d %H:%M:%S%z\",\n",
    "        )\n",
    "        .cast(pl.Datetime(\"us\", time_zone=\"UTC\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"date_of_birth\")\n",
    "        .str.strptime(\n",
    "            pl.Datetime,\n",
    "            format=\"%Y-%m-%d\",\n",
    "        )\n",
    "        .cast(pl.Datetime(\"us\", time_zone=\"UTC\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"godate\")\n",
    "        .str.strptime(\n",
    "            pl.Datetime,\n",
    "            format=\"%Y-%m-%d %H:%M:%S%z\",\n",
    "        )\n",
    "        .cast(pl.Datetime(\"us\", time_zone=\"UTC\"))\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"paidon\")\n",
    "        .str.strptime(pl.Datetime, format=\"%Y-%m-%d %H:%M:%S.%f%z\", strict=False)\n",
    "        .cast(pl.Datetime(\"us\", time_zone=\"UTC\"))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's sort all the events so that we can further split the data by booking creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_data = pl_data.sort(\"createdon\", descending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_data = pl_data.with_columns(\n",
    "    pl.col(\"channel\").fill_null(\"unknown\"),\n",
    "    pl.col(\"cust_name\").fill_null(\"unknown\"),\n",
    "    pl.col(\"nationality\").fill_null(\"unknown\"),\n",
    "    pl.col(\"payer_country\").fill_null(\"unknown\"),\n",
    "    pl.col(\"proxy\").fill_null(0.0),\n",
    "    pl.col(\"tor\").fill_null(0.0),\n",
    "    pl.col(\"vpn\").fill_null(0.0),\n",
    "    pl.col(\"recent_abuse\").fill_null(0.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date of booking 2021-04-30 17:21:17+00:00\n",
      "Max date of booking 2023-11-30 16:59:52+00:00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min date of booking {pl_data['createdon'].min()}\")\n",
    "print(f\"Max date of booking {pl_data['createdon'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l9/p8dmtkcx40g8jtfzctxzg4km0000gn/T/ipykernel_4737/566717501.py:133: DeprecationWarning: `days` is deprecated. It has been renamed to `total_days`.\n",
      "  ((pl.col(\"createdon\") - pl.col(\"date_of_birth\")).dt.days() / 365.25).alias(\n",
      "/var/folders/l9/p8dmtkcx40g8jtfzctxzg4km0000gn/T/ipykernel_4737/566717501.py:136: DeprecationWarning: `days` is deprecated. It has been renamed to `total_days`.\n",
      "  ((pl.col(\"godate\") - pl.col(\"date_of_birth\")).dt.days() / 365.25).alias(\n"
     ]
    }
   ],
   "source": [
    "# 1. Features based on email_score and other score\n",
    "pl_data = pl_data.with_columns(\n",
    "    [\n",
    "        (pl.col(\"email_score\") * pl.col(\"passenger_score\")).alias(\"score_interaction\"),\n",
    "        ((pl.col(\"email_score\") + pl.col(\"passenger_score\")) / 2).alias(\n",
    "            \"avg_risk_score\"\n",
    "        ),\n",
    "        (pl.max_horizontal([\"email_score\", \"passenger_score\"])).alias(\"max_risk_score\"),\n",
    "        # Deviation from the average score\n",
    "        (pl.col(\"email_score\") - pl.col(\"email_score\").mean()).alias(\n",
    "            \"email_score_deviation\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "# 2. Price-based features (net price_thb)\n",
    "pl_data = pl_data.with_columns(\n",
    "    [  # Price per seat\n",
    "        (pl.col(\"netprice_thb\") / pl.col(\"seats\")).alias(\"price_per_seat\"),\n",
    "        # Price deviation from the average for this type of transport\n",
    "        (\n",
    "            pl.col(\"netprice_thb\") - pl.col(\"netprice_thb\").mean().over(\"vehclass_id\")\n",
    "        ).alias(\"price_deviation\"),\n",
    "        # Percentage deviation of the price\n",
    "        (\n",
    "            (pl.col(\"netprice_thb\") - pl.col(\"netprice_thb\").mean().over(\"vehclass_id\"))\n",
    "            / pl.col(\"netprice_thb\").mean().over(\"vehclass_id\")\n",
    "            * 100\n",
    "        ).alias(\"price_deviation_percent\"),\n",
    "    ]\n",
    ")\n",
    "# 3. Security Features\n",
    "pl_data = pl_data.with_columns(\n",
    "    [\n",
    "        (\n",
    "            pl.col(\"proxy\") + pl.col(\"vpn\") + pl.col(\"tor\") + pl.col(\"recent_abuse\")\n",
    "        ).alias(\"security_flags_sum\"),\n",
    "        (\n",
    "            (pl.col(\"proxy\") + pl.col(\"vpn\") + pl.col(\"tor\") + pl.col(\"recent_abuse\"))\n",
    "            > 0\n",
    "        ).alias(\"has_security_flag\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Features based on payment attempts (p_attempts)\n",
    "pl_data = pl_data.with_columns(\n",
    "    [\n",
    "        (pl.col(\"p_attempts\") > 2).alias(\"multiple_attempts\"),\n",
    "        (pl.col(\"p_attempts\").log1p()).alias(\"log_attempts\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5. Channel aggregations\n",
    "channel_stats = pl_data.group_by(\"channel\").agg(\n",
    "    [\n",
    "        (pl.col(\"netprice_thb\").mean()).alias(\"channel_avg_price\"),\n",
    "        (pl.col(\"seats\").mean()).alias(\"channel_avg_seats\"),\n",
    "        (pl.col(\"email_score\").mean()).alias(\"channel_avg_score\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pl_data = pl_data.join(channel_stats, on=\"channel\")\n",
    "\n",
    "# 6. Combined features for the type of transport (vehclass_id)\n",
    "pl_data = pl_data.with_columns(\n",
    "    [  # Average price per seat for this type of transport\n",
    "        (\n",
    "            pl.col(\"netprice_thb\").mean().over(\"vehclass_id\")\n",
    "            / pl.col(\"seats\").mean().over(\"vehclass_id\")\n",
    "        ).alias(\"vehclass_avg_price_per_seat\"),\n",
    "        # Deviation from the average price per seat\n",
    "        (\n",
    "            (pl.col(\"netprice_thb\") / pl.col(\"seats\"))\n",
    "            - (\n",
    "                pl.col(\"netprice_thb\").mean().over(\"vehclass_id\")\n",
    "                / pl.col(\"seats\").mean().over(\"vehclass_id\")\n",
    "            )\n",
    "        ).alias(\"price_per_seat_deviation\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 7. Interactions between important features\n",
    "pl_data = pl_data.with_columns(\n",
    "    [\n",
    "        (pl.col(\"email_score\") * pl.col(\"netprice_thb\")).alias(\n",
    "            \"score_price_interaction\"\n",
    "        ),\n",
    "        (pl.col(\"email_score\") * pl.col(\"security_flags_sum\")).alias(\n",
    "            \"score_security_interaction\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 8. Features for the insurance flag (insurance_flg)\n",
    "pl_data = pl_data.with_columns(\n",
    "    [  # Price-to-average ratio with/without insurance\n",
    "        (\n",
    "            pl.col(\"netprice_thb\") / pl.col(\"netprice_thb\").mean().over(\"insurance_flg\")\n",
    "        ).alias(\"price_to_insurance_avg\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 9. Creating time-related features\n",
    "pl_data = pl_data.with_columns(\n",
    "    [  # The difference between the creation and payment time (in hours)\n",
    "        ((pl.col(\"paidon\") - pl.col(\"createdon\")).dt.total_seconds() / 3600).alias(\n",
    "            \"hours_to_pay\"\n",
    "        ),\n",
    "        # The difference between the payment and the trip (in days)\n",
    "        ((pl.col(\"godate\") - pl.col(\"paidon\")).dt.total_seconds() / (3600 * 24)).alias(\n",
    "            \"days_to_trip\"\n",
    "        ),\n",
    "        # Difference between creation and trip (in days)\n",
    "        (\n",
    "            (pl.col(\"godate\") - pl.col(\"createdon\")).dt.total_seconds() / (3600 * 24)\n",
    "        ).alias(\"days_from_creation_to_trip\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 10. We add more complex features over time\n",
    "pl_data = pl_data.with_columns(\n",
    "    [\n",
    "        (pl.col(\"hours_to_pay\") < 1 / 60).alias(\"instant_payment\"),\n",
    "        (pl.col(\"hours_to_pay\") < 5 / 60).alias(\"suspicious_fast_payment\"),\n",
    "        (pl.col(\"hours_to_pay\") > 24).alias(\"long_payment\"),\n",
    "        (pl.col(\"days_to_trip\") < 7).alias(\"near_trip\"),\n",
    "        (pl.col(\"days_to_trip\") > 90).alias(\"far_future_trip\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 11. Basic age features\n",
    "pl_data = pl_data.with_columns(\n",
    "    [\n",
    "        ((pl.col(\"createdon\") - pl.col(\"date_of_birth\")).dt.days() / 365.25).alias(\n",
    "            \"age\"\n",
    "        ),\n",
    "        ((pl.col(\"godate\") - pl.col(\"date_of_birth\")).dt.days() / 365.25).alias(\n",
    "            \"age_at_trip\"\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data by time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To separate the data, we will use the date 2023-08-01 since the distribution of the target event will be approximately the same for training and testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_split_utc = pl.datetime(2023, 8, 1, 0, 0, 0).cast(\n",
    "    pl.Datetime(\"us\", time_zone=\"UTC\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    0.99788\n",
       "1    0.00212\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data.filter(pl.col(\"createdon\") < date_split_utc)[\n",
    "    \"isFraud\"\n",
    "].to_pandas().value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    0.997435\n",
       "1    0.002565\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data.filter(pl.col(\"createdon\") >= date_split_utc)[\n",
    "    \"isFraud\"\n",
    "].to_pandas().value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    2380558\n",
       "1       5058\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data.filter(pl.col(\"createdon\") < date_split_utc)[\n",
    "    \"isFraud\"\n",
    "].to_pandas().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    1075839\n",
       "1       2767\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_data.filter(pl.col(\"createdon\") >= date_split_utc)[\n",
    "    \"isFraud\"\n",
    "].to_pandas().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and prepare cat features for Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"channel\", \"nationality\", \"payer_country\", \"role_id\", \"vehclass_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pl_data.filter(pl.col(\"createdon\") < date_split_utc)\n",
    "test_data = pl_data.filter(pl.col(\"createdon\") >= date_split_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_iso = train_data.clone()\n",
    "X_test_iso = test_data.clone()\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "for cat_col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    encoders[cat_col] = le\n",
    "\n",
    "    train_values = X_train_iso[cat_col].cast(str).to_numpy()\n",
    "    encoded_train = le.fit_transform(train_values)\n",
    "    X_train_iso = X_train_iso.with_columns(\n",
    "        pl.Series(name=f\"{cat_col}_encoded\", values=encoded_train)\n",
    "    )\n",
    "\n",
    "    test_values = X_test_iso[cat_col].cast(str).to_numpy()\n",
    "    encoded_test = [\n",
    "        le.transform([x])[0] if x in le.classes_ else -1 for x in test_values\n",
    "    ]\n",
    "    X_test_iso = X_test_iso.with_columns(\n",
    "        pl.Series(name=f\"{cat_col}_encoded\", values=encoded_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2385616, 63)\n",
      "Test shape: (1078606, 63)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", X_train_iso.shape)\n",
    "print(\"Test shape:\", X_test_iso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_features = pd.DataFrame({'Columns': X_train_iso.columns, 'Type': X_train_iso.dtypes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = X_train_iso.drop(\n",
    "    columns=[\n",
    "        \"bid\",\n",
    "        \"channel\",\n",
    "        \"createdon\",\n",
    "        \"cust_name\",\n",
    "        \"date_of_birth\",\n",
    "        \"email\",\n",
    "        \"godate\",\n",
    "        \"ip\",\n",
    "        \"nationality\",\n",
    "        \"paidon\",\n",
    "        \"payer_name\",\n",
    "        \"payer_country\",\n",
    "        \"role_id\",\n",
    "        \"useragent\",\n",
    "        \"usr_name\",\n",
    "        \"vehclass_id\",\n",
    "    ]\n",
    ").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = X_train_iso.select(final_features).to_pandas().fillna(0)\n",
    "X_test_final = X_test_iso.select(final_features).to_pandas().fillna(0)\n",
    "y_test = test_data[\"isFraud\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "X_test_scaled = scaler.transform(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_final.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.00212, \n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.00212, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest(contamination=0.00212, n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest(contamination=0.00212, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (iso_forest.predict(X_test_scaled) == -1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_scores = -iso_forest.score_samples(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00   1075839\n",
      "           1       0.30      0.33      0.31      2767\n",
      "\n",
      "    accuracy                           1.00   1078606\n",
      "   macro avg       0.65      0.66      0.66   1078606\n",
      "weighted avg       1.00      1.00      1.00   1078606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1073680    2159]\n",
      " [   1852     915]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = test_data.to_pandas()\n",
    "results_df[\"anomaly_score\"] = anomaly_scores\n",
    "results_df[\"predicted_fraud\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "False Positive Rate: 0.002001657695210299\n",
      "False Negative Rate: 0.6693169497650886\n"
     ]
    }
   ],
   "source": [
    "false_positives = results_df[\n",
    "    (results_df[\"predicted_fraud\"] == 1) & (results_df[\"isFraud\"] == 0)\n",
    "]\n",
    "false_negatives = results_df[\n",
    "    (results_df[\"predicted_fraud\"] == 0) & (results_df[\"isFraud\"] == 1)\n",
    "]\n",
    "\n",
    "print(\"\\nFalse Positive Rate:\", len(false_positives) / len(results_df))\n",
    "print(\n",
    "    \"False Negative Rate:\",\n",
    "    len(false_negatives) / len(results_df[results_df[\"isFraud\"] == 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most anomalous transactions:\n",
      "        anomaly_score  isFraud  predicted_fraud  email_score  netprice_thb\n",
      "241522       0.751966        1                1         10.0  14287.441406\n",
      "343349       0.750572        1                1         10.0  15589.012695\n",
      "125226       0.745960        1                1         10.0  10929.082031\n",
      "213723       0.743714        1                1         10.0  13225.910156\n",
      "187424       0.741908        1                1          5.0  17436.582031\n",
      "269220       0.741186        1                1         10.0   8027.323242\n",
      "241528       0.741137        1                1         10.0  14287.441406\n",
      "88543        0.740667        1                1         10.0   8997.291992\n",
      "538258       0.739042        1                1         10.0   8970.461914\n",
      "187345       0.738417        1                1          5.0  28198.468750\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTop 10 most anomalous transactions:\")\n",
    "print(\n",
    "    results_df.nlargest(10, \"anomaly_score\")[\n",
    "        [\"anomaly_score\", \"isFraud\", \"predicted_fraud\", \"email_score\", \"netprice_thb\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kurmangazykarabekov/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/kurmangazykarabekov/anaconda3/lib/python3.11/site-packages/numpy/lib/function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature correlations with anomaly scores (top 10):\n",
      "                        feature  correlation\n",
      "20           security_flags_sum     0.702468\n",
      "21            has_security_flag     0.610482\n",
      "8                         proxy     0.610474\n",
      "9                  recent_abuse     0.587580\n",
      "12                          vpn     0.551721\n",
      "30   score_security_interaction     0.394026\n",
      "45              role_id_encoded    -0.355283\n",
      "27  vehclass_avg_price_per_seat     0.347881\n",
      "23                 log_attempts     0.315284\n",
      "5                    p_attempts     0.277389\n"
     ]
    }
   ],
   "source": [
    "temp_df = X_test_final.copy()\n",
    "temp_df[\"anomaly_score\"] = anomaly_scores\n",
    "\n",
    "correlations = temp_df.corrwith(temp_df[\"anomaly_score\"])\n",
    "\n",
    "feature_importance = pd.DataFrame(\n",
    "    {\n",
    "        \"feature\": correlations.index[:-1],  \n",
    "        \"correlation\": correlations.values[:-1],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\nFeature correlations with anomaly scores (top 10):\")\n",
    "print(feature_importance.sort_values(\"correlation\", key=abs, ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
